{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Optimizing the Text Generation Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCxhW3mtLmfb"
      },
      "source": [
        "You've already done some amazing work with generating new songs, but so far we've seen some issues with repetition and a fair amount of incoherence. By using more data and further tweaking the model, you'll be able to get improved results. We'll once again use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics) here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Bf5FVHfganK",
        "outputId": "14936581-3e76-4b44-e8ce-9d8c2c720977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-20 07:02:08--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 172.253.117.102, 172.253.117.100, 172.253.117.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.253.117.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/aodac5abbnlo906tk85a5365pmqf7fsd/1684566075000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=cd26de28-c872-4f33-a544-8db3a143c122 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-05-20 07:02:12--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/aodac5abbnlo906tk85a5365pmqf7fsd/1684566075000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=cd26de28-c872-4f33-a544-8db3a143c122\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 74.125.20.132, 2607:f8b0:400e:c07::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M   101MB/s    in 0.7s    \n",
            "\n",
            "2023-05-20 07:02:13 (101 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz9x-7dWihxx"
      },
      "source": [
        "## 250 Songs\n",
        "\n",
        "Now we've seen a model trained on just a small sample of songs, and how this often leads to repetition as you get further along in trying to generate new text. Let's switch to using the 250 songs instead, and see if our output improves. This will actually be nearly 10K lines of lyrics, which should be sufficient.\n",
        "\n",
        "Note that we won't use the full dataset here as it will take up quite a bit of RAM and processing time, but you're welcome to try doing so on your own later. If interested, you'll likely want to use only some of the more common words for the Tokenizer, which will help shrink processing time and memory needed (or else you'd have an output array hundreds of thousands of words long)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWbMN_19jfRT"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LRmPPJegovBe"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kIGedF3XjHj4",
        "outputId": "c6020dcc-e8ec-4172-b809-1ce7e4ff8c1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-fbdddccf8583>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n"
          ]
        }
      ],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "# Read the dataset from csv - this time with 250 songs\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
        "total_words = tokenizer.num_words\n",
        "\n",
        "# There should be a lot more words now\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quoDmw_FkNBA"
      },
      "source": [
        "### Create Sequences and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kkLAf3HmkPSo"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cECbqT-blMk-"
      },
      "source": [
        "### Train a (Better) Text Generation Model\n",
        "\n",
        "With more data, we'll cut off after 100 epochs to avoid keeping you here all day. You'll also want to change your runtime type to GPU if you haven't already (you'll need to re-run the above cells if you change runtimes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7nHOp6uWlP_P",
        "outputId": "2196b183-b4f2-4804-e9d8-75d2237c4977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1480/1480 [==============================] - 30s 14ms/step - loss: 5.9868 - accuracy: 0.0458\n",
            "Epoch 2/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.6979 - accuracy: 0.0502\n",
            "Epoch 3/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 5.4914 - accuracy: 0.0697\n",
            "Epoch 4/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.2686 - accuracy: 0.1001\n",
            "Epoch 5/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 5.0813 - accuracy: 0.1127\n",
            "Epoch 6/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.9043 - accuracy: 0.1302\n",
            "Epoch 7/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 4.7503 - accuracy: 0.1505\n",
            "Epoch 8/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 4.6146 - accuracy: 0.1660\n",
            "Epoch 9/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.4967 - accuracy: 0.1785\n",
            "Epoch 10/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.3908 - accuracy: 0.1924\n",
            "Epoch 11/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 4.2925 - accuracy: 0.2048\n",
            "Epoch 12/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 4.2051 - accuracy: 0.2168\n",
            "Epoch 13/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 4.1226 - accuracy: 0.2258\n",
            "Epoch 14/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.0480 - accuracy: 0.2334\n",
            "Epoch 15/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.9755 - accuracy: 0.2425\n",
            "Epoch 16/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.9158 - accuracy: 0.2504\n",
            "Epoch 17/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.8535 - accuracy: 0.2583\n",
            "Epoch 18/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.7992 - accuracy: 0.2655\n",
            "Epoch 19/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.7502 - accuracy: 0.2718\n",
            "Epoch 20/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.6978 - accuracy: 0.2805\n",
            "Epoch 21/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.6519 - accuracy: 0.2868\n",
            "Epoch 22/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.6050 - accuracy: 0.2947\n",
            "Epoch 23/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.5674 - accuracy: 0.2989\n",
            "Epoch 24/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.5279 - accuracy: 0.3059\n",
            "Epoch 25/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.4868 - accuracy: 0.3105\n",
            "Epoch 26/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.4515 - accuracy: 0.3167\n",
            "Epoch 27/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.4135 - accuracy: 0.3204\n",
            "Epoch 28/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.3824 - accuracy: 0.3254\n",
            "Epoch 29/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.3453 - accuracy: 0.3322\n",
            "Epoch 30/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.3163 - accuracy: 0.3359\n",
            "Epoch 31/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.2825 - accuracy: 0.3404\n",
            "Epoch 32/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.2556 - accuracy: 0.3449\n",
            "Epoch 33/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.2261 - accuracy: 0.3499\n",
            "Epoch 34/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.2034 - accuracy: 0.3533\n",
            "Epoch 35/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.1736 - accuracy: 0.3582\n",
            "Epoch 36/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.1504 - accuracy: 0.3605\n",
            "Epoch 37/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.1270 - accuracy: 0.3653\n",
            "Epoch 38/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.1000 - accuracy: 0.3671\n",
            "Epoch 39/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.0731 - accuracy: 0.3734\n",
            "Epoch 40/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.0575 - accuracy: 0.3760\n",
            "Epoch 41/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.0340 - accuracy: 0.3778\n",
            "Epoch 42/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.0108 - accuracy: 0.3825\n",
            "Epoch 43/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9840 - accuracy: 0.3868\n",
            "Epoch 44/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.9689 - accuracy: 0.3891\n",
            "Epoch 45/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9522 - accuracy: 0.3916\n",
            "Epoch 46/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9342 - accuracy: 0.3952\n",
            "Epoch 47/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.9134 - accuracy: 0.3981\n",
            "Epoch 48/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8941 - accuracy: 0.4025\n",
            "Epoch 49/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.8799 - accuracy: 0.4051\n",
            "Epoch 50/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8629 - accuracy: 0.4069\n",
            "Epoch 51/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8412 - accuracy: 0.4106\n",
            "Epoch 52/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8289 - accuracy: 0.4132\n",
            "Epoch 53/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8147 - accuracy: 0.4173\n",
            "Epoch 54/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.7938 - accuracy: 0.4199\n",
            "Epoch 55/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.7822 - accuracy: 0.4227\n",
            "Epoch 56/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.7706 - accuracy: 0.4215\n",
            "Epoch 57/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7511 - accuracy: 0.4246\n",
            "Epoch 58/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.7530 - accuracy: 0.4267\n",
            "Epoch 59/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.7288 - accuracy: 0.4306\n",
            "Epoch 60/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7236 - accuracy: 0.4318\n",
            "Epoch 61/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.6916 - accuracy: 0.4366\n",
            "Epoch 62/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6908 - accuracy: 0.4360\n",
            "Epoch 63/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6765 - accuracy: 0.4397\n",
            "Epoch 64/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6643 - accuracy: 0.4419\n",
            "Epoch 65/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6467 - accuracy: 0.4444\n",
            "Epoch 66/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6318 - accuracy: 0.4467\n",
            "Epoch 67/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.6253 - accuracy: 0.4481\n",
            "Epoch 68/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.6173 - accuracy: 0.4502\n",
            "Epoch 69/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.6075 - accuracy: 0.4494\n",
            "Epoch 70/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.5875 - accuracy: 0.4541\n",
            "Epoch 71/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.5800 - accuracy: 0.4558\n",
            "Epoch 72/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5722 - accuracy: 0.4581\n",
            "Epoch 73/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5704 - accuracy: 0.4585\n",
            "Epoch 74/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.5483 - accuracy: 0.4634\n",
            "Epoch 75/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.5330 - accuracy: 0.4649\n",
            "Epoch 76/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.5337 - accuracy: 0.4648\n",
            "Epoch 77/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.5162 - accuracy: 0.4669\n",
            "Epoch 78/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.5041 - accuracy: 0.4697\n",
            "Epoch 79/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.5001 - accuracy: 0.4707\n",
            "Epoch 80/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4955 - accuracy: 0.4700\n",
            "Epoch 81/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4754 - accuracy: 0.4758\n",
            "Epoch 82/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4715 - accuracy: 0.4747\n",
            "Epoch 83/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4748 - accuracy: 0.4743\n",
            "Epoch 84/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4581 - accuracy: 0.4779\n",
            "Epoch 85/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4390 - accuracy: 0.4829\n",
            "Epoch 86/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4412 - accuracy: 0.4799\n",
            "Epoch 87/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4307 - accuracy: 0.4816\n",
            "Epoch 88/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4182 - accuracy: 0.4845\n",
            "Epoch 89/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4077 - accuracy: 0.4886\n",
            "Epoch 90/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3967 - accuracy: 0.4901\n",
            "Epoch 91/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3924 - accuracy: 0.4898\n",
            "Epoch 92/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3815 - accuracy: 0.4922\n",
            "Epoch 93/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3754 - accuracy: 0.4933\n",
            "Epoch 94/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3708 - accuracy: 0.4936\n",
            "Epoch 95/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3595 - accuracy: 0.4960\n",
            "Epoch 96/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3554 - accuracy: 0.4959\n",
            "Epoch 97/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3780 - accuracy: 0.4932\n",
            "Epoch 98/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4029 - accuracy: 0.4887\n",
            "Epoch 99/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3423 - accuracy: 0.5012\n",
            "Epoch 100/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3265 - accuracy: 0.5029\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgvIz20nlQcq"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rOqmmarvlSLh",
        "outputId": "d4fdf5a1-a907-4be6-b8ce-19ec34a817aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISLZZGlQlSxh"
      },
      "source": [
        "### Generate better lyrics!\n",
        "\n",
        "This time around, we should be able to get a more interesting output with less repetition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "P96oVMk3lU7y",
        "outputId": "43408837-8d91-42eb-915b-2798f2cc423b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 638ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "im feeling chills to blame it all all day in the road of my bus you song living story fireplace thousand turn kick andante brother drop drop thousand ahhaha books darkness runner awhile doing what if i cant go out of time of us around my room for help little other marionette tree window promise treasure treasure vision vision masters drop whirl played whirl tuviera oasis turn court darkness ladies sea winter promise scars livingstone neighbor rockn roller jeanie jeanie jeanie jeanie jeanie jeanie jeanie jeanie beneath tip my trembling dancing hotels gimme blue stuff knock mudda drop vision guiding drop whirl question\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgJKV8_oRU9"
      },
      "source": [
        "### Varying the Possible Outputs\n",
        "\n",
        "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n",
        "\n",
        "Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lZe9gaJeoGVP",
        "outputId": "01fc5e4c-62ea-4455-dbf7-38f38393d393",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "96\n"
          ]
        }
      ],
      "source": [
        "# Test the method with just the first word after the seed text\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "predicted_probs = model.predict(token_list)[0]\n",
        "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
        "                             p=predicted_probs)\n",
        "# Running this cell multiple times should get you some variance in output\n",
        "print(predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ee7WKgRGrJy1",
        "outputId": "659b1a34-65e8-4727-e696-24e1fe4f2093",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "im feeling chills into a little woman the woman around ahhah roll hello broken a fan gonna sail hug croissants question beating hug chuck voulezvous season season another horns of his embers darkness pretty claridad boys story bar pneumonia loneliness parted fade choose images answer ahhaha desire and low goin different ground letters birds mother known got to ya spell merry woogie smells books beating chance jeanie why livin back what to here myself from you get or no tricks aint happening though anything think that i just baby on turn hug me cant look hug five baby beep and sunrise all wind\n"
          ]
        }
      ],
      "source": [
        "# Use this process for the full output generation\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted_probs = model.predict(token_list)[0]\n",
        "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
        "                               p=predicted_probs)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l10c04_nlp_optimizing_the_text_generation_model.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}